{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight dtypes: {dtype('float32')}\n",
      "I/O dtypes: {dtype('float32')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lg/ltf4rt5x5_7b6r3d1ty50m3h0000gq/T/ipykernel_33686/491560778.py:9: DeprecationWarning: `mapping.TENSOR_TYPE_TO_NP_TYPE` is now deprecated and will be removed in a future release.To silence this warning, please use `helper.tensor_dtype_to_np_dtype` instead.\n",
      "  mapping.TENSOR_TYPE_TO_NP_TYPE[t.data_type]\n",
      "/var/folders/lg/ltf4rt5x5_7b6r3d1ty50m3h0000gq/T/ipykernel_33686/491560778.py:18: DeprecationWarning: `mapping.TENSOR_TYPE_TO_NP_TYPE` is now deprecated and will be removed in a future release.To silence this warning, please use `helper.tensor_dtype_to_np_dtype` instead.\n",
      "  io_types.add(mapping.TENSOR_TYPE_TO_NP_TYPE[t])\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "from onnx import helper, mapping\n",
    "\n",
    "# load your model\n",
    "model = onnx.load(\"models/w600k_mbf.onnx\")\n",
    "\n",
    "# collect all initializer (weight) dtypes\n",
    "dtypes = {\n",
    "    mapping.TENSOR_TYPE_TO_NP_TYPE[t.data_type]\n",
    "    for t in model.graph.initializer\n",
    "}\n",
    "print(\"Weight dtypes:\", dtypes)\n",
    "\n",
    "# also check all graph inputs and outputs\n",
    "io_types = set()\n",
    "for io in list(model.graph.input) + list(model.graph.output):\n",
    "    t = io.type.tensor_type.elem_type\n",
    "    io_types.add(mapping.TENSOR_TYPE_TO_NP_TYPE[t])\n",
    "print(\"I/O dtypes:\", io_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input `input.1`: tensor(float)\n",
      "Output `443`: tensor(float)\n",
      "Output `468`: tensor(float)\n",
      "Output `493`: tensor(float)\n",
      "Output `446`: tensor(float)\n",
      "Output `471`: tensor(float)\n",
      "Output `496`: tensor(float)\n",
      "Output `449`: tensor(float)\n",
      "Output `474`: tensor(float)\n",
      "Output `499`: tensor(float)\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime as ort\n",
    "\n",
    "sess = ort.InferenceSession(\"models/det_500m.onnx\")\n",
    "for inp in sess.get_inputs():\n",
    "    print(f\"Input `{inp.name}`: {inp.type}\")   # e.g. \"tensor(float)\"\n",
    "for out in sess.get_outputs():\n",
    "    print(f\"Output `{out.name}`: {out.type}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied 400 images from\n",
      "  /Users/yousufsarfraz_1/Downloads/archive (4)/images/train\n",
      "to\n",
      "  /Users/yousufsarfraz_1/Documents/GitHub/mds-25/downsizing_experimental/calibration_images_v2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "# 1. Update these paths to your source and target directories:\n",
    "src_dir = '/Users/yousufsarfraz_1/Downloads/archive (4)/images/train'\n",
    "dst_dir = '/Users/yousufsarfraz_1/Documents/GitHub/mds-25/downsizing_experimental/calibration_images_v2'\n",
    "\n",
    "# Create target directory if it doesn't exist\n",
    "os.makedirs(dst_dir, exist_ok=True)\n",
    "\n",
    "# 2. Collect all .png files from the source directory\n",
    "png_files = [f for f in os.listdir(src_dir)]\n",
    "\n",
    "# 3. Randomly sample up to 400 files\n",
    "sample_count = min(400, len(png_files))\n",
    "sampled_files = random.sample(png_files, sample_count)\n",
    "\n",
    "# 4. Copy each sampled file to the target directory\n",
    "for filename in sampled_files:\n",
    "    src_path = os.path.join(src_dir, filename)\n",
    "    dst_path = os.path.join(dst_dir, filename)\n",
    "    shutil.copy(src_path, dst_path)\n",
    "\n",
    "print(f\"Copied {sample_count} images from\\n  {src_dir}\\nto\\n  {dst_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Please consider to run pre-processing before quantization. Refer to example: https://github.com/microsoft/onnxruntime-inference-examples/blob/main/quantization/image_classification/cpu/ReadMe.md \n",
      "WARNING:root:Please consider pre-processing before quantization. See https://github.com/microsoft/onnxruntime-inference-examples/blob/main/quantization/image_classification/cpu/ReadMe.md \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Static INT8 quantized model saved to: /Users/yousufsarfraz_1/Documents/GitHub/mds-25/downsizing_experimental/det_500m.static_int8_v2.onnx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import onnxruntime\n",
    "from onnxruntime.quantization import quantize_static, CalibrationDataReader, QuantType\n",
    "\n",
    "# Paths\n",
    "model_input = \"/Users/yousufsarfraz_1/.insightface/models/buffalo_sc/det_500m.onnx\"\n",
    "model_output = \"/Users/yousufsarfraz_1/Documents/GitHub/mds-25/downsizing_experimental/det_500m.static_int8_v2.onnx\"\n",
    "calib_folder = \"/Users/yousufsarfraz_1/Documents/GitHub/mds-25/downsizing_experimental/calibration_images_v2\"\n",
    "\n",
    "# 1. Create an ONNX Runtime session to fetch the input name\n",
    "session = onnxruntime.InferenceSession(model_input, providers=[\"CPUExecutionProvider\"])\n",
    "input_name = session.get_inputs()[0].name\n",
    "\n",
    "# 2. Calibration data reader\n",
    "class FaceCalibReader(CalibrationDataReader):\n",
    "    def __init__(self, image_folder, input_name):\n",
    "        self.image_paths = [\n",
    "            os.path.join(image_folder, f)\n",
    "            for f in os.listdir(image_folder)\n",
    "            if f.lower().endswith((\".jpg\", \".jpeg\", \".png\"))\n",
    "        ]\n",
    "        self.input_name = input_name\n",
    "        self.iter = iter(self.image_paths)\n",
    "\n",
    "    def get_next(self):\n",
    "        try:\n",
    "            img_path = next(self.iter)\n",
    "            # Load image (BGR), resize, convert to RGB\n",
    "            img = cv2.imread(img_path)\n",
    "            img = cv2.resize(img, (640, 640))\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            # Normalize to [0,1], transpose to (C,H,W), add batch dim\n",
    "            img = img.astype(np.float32) / 255.0\n",
    "            img = np.transpose(img, (2, 0, 1))[None, ...]\n",
    "            return {self.input_name: img}\n",
    "        except StopIteration:\n",
    "            return None\n",
    "\n",
    "calib_reader = FaceCalibReader(calib_folder, input_name)\n",
    "\n",
    "# 3. Run static quantization\n",
    "quantize_static(\n",
    "    model_input=model_input,\n",
    "    model_output=model_output,\n",
    "    calibration_data_reader=calib_reader,\n",
    "    activation_type=QuantType.QInt8,\n",
    "    weight_type=QuantType.QInt8\n",
    ")\n",
    "\n",
    "print(f\"Static INT8 quantized model saved to: {model_output}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
